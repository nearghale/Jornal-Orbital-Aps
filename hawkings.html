<html lang="es">
<head>
<title>Lixo Espacial</title>
<link rel="shortcut icon" href="icones/earth.gif">
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1, maximum-scale=1, minimum-scale=1">
<link rel="stylesheet" href="estilosa.css">
</head>
<body>

<header>
<input type="checkbox" id="btn-menu">
<label for="btn-menu"><img src="icones/icon-menu.png" alt="" width="47" height="31">
</label>
<nav id="menu">
<ul>
<li class="fd"></li>
		<li><a href="index.html">Início</a></li>
			<li><a href="hawkings.html">Tema</a></li>
			<li><a href="solucao.html">Solução</a></li>
			<li><a href="desenvolvedores.html">Produtores</a></li>
</ul>
</nav>
</header>
<div class="corpo"></div>

  <div class="t">
  <div class="container">
			<div class="Titulo">
			<span class="font-semibold">Inteligência Artificial</span></div>
			</div>
			<div class="barra">
				<div class="hr">&nbsp;</div>
			</div>
            <main>
            <p> Stephen Hawking acredita que os esforços para criar máquinas que pensem sozinhas são uma ameaça à nossa existência.

"O desenvolvimento de uma inteligência artificial total (AI) pode levar ao fim da raça humana", disse o físico à BBC em 2014.

Segundo ele, as formas primitivas de inteligência artificial desenvolvidas até o momento já provaram ser úteis, mas Hawking teme as consequências de se criar algo que possa se igualar ou até superar os humanos.

"(As máquinas) iriam evoluir sozinhas, refazer o próprio projeto a uma velocidade cada vez maior. Humanos, que são limitados por uma evolução biológica lenta, não poderiam competir e seriam substituídos."

Hawking não é o único que teme a inteligência artificial. O cinema americano já tratou a questão como uma ameaça em vários filmes como 2001: Uma Odisseia no Espaço (de 1968), Bladerunner (de 1982), a série de filmes O Exterminador do Futuro, entre outros.
</p>

            </main>
   </div>
  <div class="t">
    <div class="container">
			<div class="Titulo">
			<span class="font-semibold">Guerra Nuclear</span></div>
			</div>
			<div class="barra">
				<div class="hr">&nbsp;</div>
			</div>
             <p> Se as máquinas não nos matarem, nós poderemos fazer isso por conta própria.

"O fracasso humano que eu mais gostaria de corrigir é a agressão", disse Hawking em uma palestra no Museu da Ciência de Londres, em 2015.

"Pode ter sido uma vantagem para a sobrevivência na época dos homens das cavernas, para conseguir mais comida, território ou parceiros para reprodução, mas agora é uma ameaça que pode destruir todos nós."

As armas de destruição em massa atuais são capazes de acabar com a vida na Terra, e a proliferação dos arsenais nucleares é uma grande preocupação mundial.

"Uma grande guerra mundial significaria o fim da civilização e talvez o fim da raça humana", disse Hawking.</p>
   </div>
  </div>
  <div class="t">
    <div class="container">
			<div class="Titulo">
			<span class="font-semibold">Vírus criado por engenharia genética</span></div>
			</div>
			<div class="barra">
				<div class="hr">&nbsp;</div>
			</div>
            <main><p>
			E as armas nucleares podem não ser a pior ameaça entre as invenções da humanidade.

Em 2001, Hawking disse ao jornal britânico Daily Telegraph que a raça humana enfrenta a perspectiva de ser exterminada por um vírus criado por ela mesma.

"No longo prazo, fico mais preocupado com a biologia. Armas nucleares precisam de instalações grandes, mas engenharia genética pode ser feita em um pequeno laboratório. Você não consegue regulamentar cada laboratório do mundo. O perigo é que, seja por um acidente ou algo planejado, criemos um vírus que possa nos destruir", disse o cientista ao jornal.

"Não acho que a raça humana vai sobreviver aos próximos mil anos, a não ser que nos espalhemos pelo espaço. Há muitos acidentes que podem afetar a vida em um único planeta."

Novamente, temores como esse já foram retratados por Hollywood. Filmes como 12 Macacos, Eu Sou A Lenda e a série Resident Evil são apenas alguns dos que mostram um cenário no qual vírus feitos pelos homens destroem a sociedade.</p></div>
  </div>
  </div>



 <div class="t">
    <div class="container">
			<div class="Titulo">
			<span class="font-semibold">Aquecimento global</span></div>
			</div>
			<div class="barra">
				<div class="hr">&nbsp;</div>
			</div>
             <p> Stephen Hawking descreveu um cenário futurístico apocalíptico no documentário A Última Hora, de 2007.

"Uma das consequências mais graves de nossas ações é o aquecimento global, causado pela emissão de crescentes níveis de dióxido de carbono resultantes da queima de combustíveis fósseis. O perigo é que o aumento da temperatura se transforme em (um processo) autossustentável, se é que já não está assim."

"Secas e devastação de florestas estão reduzindo a quantidade de CO2 que é reciclada na atmosfera", afirmou.

"Além disso, o derretimento das calotas polares vai reduzir a quantidade de energia solar refletida de volta para o espaço e assim aumentar ainda mais a temperatura. Não sabemos se o aquecimento global vai parar, mas o pior cenário possível é que a Terra se transforme em um planeta como Vênus, com uma temperatura de 250 graus na superfície e chuvas de ácido sulfúrico."

"A raça humana não pode sobreviver nestas condições", acrescentou.</p>
  
   
   
   

             <p>     Hawking ainda diz que a Terra passará por outra extinção em massa,
causadas pelas alterações climáticas pelo aquecimento global, guerras e vírus
modificados, e ainda acredita que há um risco maior para a terra sofrer um impacto
com um asteroide e forçar os humanos a colonizar outros planetas e o espaço.
  <br/>
  Hawking falou em abandonar a terra, mas a primeira viagem do Homem para
Marte será em 2023, podendo ser umas das possíveis colônias humanas, mas para
chegar lá, a Espaçonave deverá passar pela Orbita Terrestre, onde há um acumulo
de mais de meio milhão e isto apresenta um risco às naves, pois os detritos podem
viajar segundo um Levantamento da NASA em 2013 em pouco mais de 28 mil
quilômetros por Hora.  </p>
   </div>
   

<div>
&nbsp;<br/>&nbsp;<br/>&nbsp;<br/>&nbsp;<br/><br/>
</div>
<footer>
    <div class="wrapper">
    
        <ul>
            <h4>Ruan Rodrigo Rene Lima de Souza</h4>
            <li class="tl">(11)98222-1523</li>
            <li class="mp">São Paulo - Brasil</li>
        </ul> <ul>
            <h4>Celso Avelino Araújo da Silva</h4>
            <li class="tl">(11)98387-8747</li>
            <li class="mp">São Paulo - Brasil</li>
        </ul> <ul>
            <h4>Matheus Eduardo Barbosa</h4>
            <li class="tl">(11)97733-6086</li>
            <li class="mp">São Paulo - Brasil</li>
        </ul> <ul>
            <li> <h4>Lucas Antonio Borges P dos Anjos</h4></li>
            <li class="tl">(11)98402-2313</li>
            <li class="mp">São Paulo - Brasil</li>
        </ul>
        <ul>
            <h4>Gabriel Ribeiro do Carmo</h4>
            <li class="tl">(11)987997910</li>
            <li class="mp">São Paulo - Brasil</li>
        </ul>


        <ul>
            <h4>Gabriel Maia Garcia	</h4>
            <li class="tl">(11)987997910</li>
            <li class="mp">São Paulo - Brasil</li>
        </ul>
		<ul>
			<li><a href="form.html" class="Fale"> <font size="4"  >  Fale Conosco</font></font></a></li>
		</ul>

		<ul>
        <div id="copyright">&copy; 2018  - Problematização Orbital; Todos os direitos reservados;    APS - Universidade Paulista.</div>
	</ul>
    </div>
	
</footer>
</body>
</html>
